"""AI Engine service using Google GenAI SDK with Pattern System Integration.

ì •í™•ë„ ë° ì‹ ë¢°ë„ í–¥ìƒ ì „ëµ:
1. ë™ì  í”„ë¡¬í”„íŠ¸ ë¹Œë” í†µí•©
2. ì‹œí—˜ì§€ ìœ í˜• ìë™ ë¶„ë¥˜ (ë¹ˆì‹œí—˜ì§€/í•™ìƒë‹µì•ˆ/ì±„ì ì—¬ë¶€)
3. ì˜¤ë¥˜ íŒ¨í„´ ê¸°ë°˜ ë¶„ì„
4. íŒ¨í„´ ë§¤ì¹­ ì´ë ¥ ì¶”ì 
5. Chain of Thought í”„ë¡¬í”„íŒ…
"""
import json
from pathlib import Path
from typing import Any

from google import genai
from google.genai import types
from fastapi import HTTPException, status

from app.core.config import settings
from app.db.supabase_client import SupabaseClient
from app.schemas.pattern import (
    ExamContext,
    BuildPromptRequest,
    ExamPaperClassification,
    QuestionAnswerInfo,
)


class AIEngine:
    """Service for interacting with AI models with Pattern System Integration."""

    def __init__(self):
        self.api_key = settings.GEMINI_API_KEY
        self.model_name = settings.GEMINI_MODEL_NAME

        # Initialize client
        if self.api_key:
            self.client = genai.Client(api_key=self.api_key)
        else:
            self.client = None

    # ============================================
    # 1. ì‹œí—˜ì§€ ìœ í˜• ìë™ ë¶„ë¥˜
    # ============================================
    async def classify_exam_paper(
        self,
        file_path: str,
    ) -> ExamPaperClassification:
        """ì‹œí—˜ì§€ ìœ í˜• ìë™ ë¶„ë¥˜ (ë¹ˆì‹œí—˜ì§€/í•™ìƒë‹µì•ˆ/ì±„ì ìƒíƒœ)"""
        if not self.client:
            # ê¸°ë³¸ê°’ ë°˜í™˜
            return ExamPaperClassification(
                paper_type="unknown",
                confidence=0.0,
                indicators=["AI ì„œë¹„ìŠ¤ ë¯¸ì„¤ì •"],
                grading_status="unknown",
            )

        # íŒŒì¼ ë¡œë“œ
        file_paths = [p.strip() for p in file_path.split(",")]
        file_parts = []

        for fp in file_paths:
            try:
                file_content, mime_type = await self._load_file_content(fp)
                if file_content:
                    file_parts.append(types.Part.from_bytes(data=file_content, mime_type=mime_type))
            except Exception as e:
                print(f"[Classification] Error loading file {fp}: {e}")
                continue

        if not file_parts:
            return ExamPaperClassification(
                paper_type="unknown",
                confidence=0.0,
                indicators=["íŒŒì¼ ì—†ìŒ"],
                grading_status="unknown",
            )

        # ë¶„ë¥˜ í”„ë¡¬í”„íŠ¸
        classification_prompt = """ì´ ì‹œí—˜ì§€ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ì—¬ ìœ í˜•ì„ ë¶„ë¥˜í•´ì£¼ì„¸ìš”.

## ë¶„ë¥˜ í•­ëª©

1. paper_type (ì‹œí—˜ì§€ ìœ í˜•):
   - "blank": ë¹ˆ ì‹œí—˜ì§€ (ë‹µì•ˆ ì—†ìŒ)
   - "answered": í•™ìƒ ë‹µì•ˆ ì‘ì„±ë¨
   - "mixed": ì¼ë¶€ë§Œ ë‹µì•ˆ ìˆìŒ

2. grading_status (ì±„ì  ìƒíƒœ):
   - "not_graded": ì±„ì  ì•ˆë¨
   - "partially_graded": ì¼ë¶€ë§Œ ì±„ì 
   - "fully_graded": ì „ì²´ ì±„ì ë¨

3. ë¬¸í•­ë³„ ì •ë³´ (ê°€ëŠ¥í•œ ê²½ìš°)

## íŒë‹¨ ê¸°ì¤€
- ì†ê¸€ì”¨ ë‹µì•ˆ ìœ ë¬´
- ì±„ì  í‘œì‹œ (O, X, â—‹, âœ—, ë™ê·¸ë¼ë¯¸, ì²´í¬)
- ì ìˆ˜ ê¸°ì¬ ì—¬ë¶€
- ë¹¨ê°„íœ/íŒŒë€íœ í‘œì‹œ

## ì‘ë‹µ í˜•ì‹ (JSON)
{
    "paper_type": "answered",
    "paper_type_confidence": 0.95,
    "paper_type_indicators": ["ì†ê¸€ì”¨ ë‹µì•ˆ ê°ì§€", "ì—¬ëŸ¬ ë¬¸í•­ì— ë‹µì•ˆ ì‘ì„±"],
    "grading_status": "fully_graded",
    "grading_confidence": 0.90,
    "grading_indicators": ["O/X í‘œì‹œ ë°œê²¬", "ì ìˆ˜ ê¸°ì¬ í™•ì¸"],
    "total_questions": 10,
    "question_details": [
        {
            "question_number": 1,
            "has_answer": true,
            "has_grading_mark": true,
            "grading_result": "correct",
            "confidence": 0.95
        }
    ],
    "summary": {
        "answered_count": 10,
        "correct_count": 7,
        "incorrect_count": 3,
        "blank_count": 0
    }
}
"""

        try:
            all_parts = file_parts + [types.Part.from_text(text=classification_prompt)]

            response = self.client.models.generate_content(
                model=self.model_name,
                contents=[
                    types.Content(role="user", parts=all_parts),
                ],
                config=types.GenerateContentConfig(
                    response_mime_type="application/json",
                    temperature=0.1,
                    max_output_tokens=4096,
                ),
            )

            if not response.text:
                raise ValueError("Empty response")

            result = self._parse_json_response(response.text)

            # ExamPaperClassification ê°ì²´ë¡œ ë³€í™˜
            question_details = []
            for q in result.get("question_details", []):
                grading_result = q.get("grading_result")
                if grading_result == "correct":
                    answer_status = "correct"
                elif grading_result == "incorrect":
                    answer_status = "incorrect"
                elif not q.get("has_answer"):
                    answer_status = "blank"
                else:
                    answer_status = "unknown"

                question_details.append(QuestionAnswerInfo(
                    question_number=q.get("question_number", 0),
                    answer_status=answer_status,
                    has_grading_mark=q.get("has_grading_mark", False),
                    grading_result=answer_status if q.get("has_grading_mark") else None,
                    confidence=q.get("confidence", 0.5),
                ))

            summary = result.get("summary") or {}

            return ExamPaperClassification(
                paper_type=result.get("paper_type", "unknown"),
                confidence=result.get("paper_type_confidence") or 0.5,
                indicators=result.get("paper_type_indicators") or [],
                grading_status=result.get("grading_status", "unknown"),
                grading_indicators=result.get("grading_indicators") or [],
                question_details=question_details,
                total_questions=result.get("total_questions") or 0,
                answered_count=summary.get("answered_count") or 0,
                correct_count=summary.get("correct_count") or 0,
                incorrect_count=summary.get("incorrect_count") or 0,
                blank_count=summary.get("blank_count") or 0,
            )

        except Exception as e:
            print(f"[Classification Error] {e}")
            return ExamPaperClassification(
                paper_type="unknown",
                confidence=0.0,
                indicators=[f"ë¶„ë¥˜ ì‹¤íŒ¨: {str(e)}"],
                grading_status="unknown",
            )

    # ============================================
    # 2. ë™ì  í”„ë¡¬í”„íŠ¸ ìƒì„±
    # ============================================
    async def build_dynamic_prompt(
        self,
        db: SupabaseClient,
        exam_context: ExamContext,
        include_error_patterns: bool = True,
        include_examples: bool = True,
    ) -> str:
        """íŒ¨í„´ DB ê¸°ë°˜ ë™ì  í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        from app.services.prompt_builder import PromptBuilder

        try:
            builder = PromptBuilder(db)
            request = BuildPromptRequest(
                exam_context=exam_context,
                include_error_patterns=include_error_patterns,
                include_examples=include_examples,
                max_examples_per_pattern=2,
            )
            result = await builder.build(request)
            return result.combined_prompt
        except Exception as e:
            print(f"[Dynamic Prompt Error] {e}")
            # í´ë°±: ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ë°˜í™˜
            if exam_context.exam_paper_type == "blank":
                return self._get_blank_prompt()
            else:
                return self._get_student_prompt()

    # ============================================
    # 3. í†µí•© ë¶„ì„ (íŒ¨í„´ ì‹œìŠ¤í…œ í¬í•¨)
    # ============================================
    async def analyze_exam_with_patterns(
        self,
        db: SupabaseClient,
        file_path: str,
        grade_level: str | None = None,
        unit: str | None = None,
        auto_classify: bool = True,
        exam_id: str | None = None,
    ) -> dict:
        """
        íŒ¨í„´ ì‹œìŠ¤í…œì„ í™œìš©í•œ í†µí•© ë¶„ì„

        Args:
            db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
            file_path: ë¶„ì„í•  íŒŒì¼ ê²½ë¡œ (ì—¬ëŸ¬ ì´ë¯¸ì§€ì¸ ê²½ìš° ì½¤ë§ˆë¡œ êµ¬ë¶„)
            grade_level: í•™ë…„ (ì˜ˆ: "ì¤‘1", "ê³ 1")
            unit: ë‹¨ì› (ì˜ˆ: "ì´ì°¨ë°©ì •ì‹")
            auto_classify: ì‹œí—˜ì§€ ìœ í˜• ìë™ ë¶„ë¥˜ ì—¬ë¶€

        Returns:
            ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        # í—¬í¼: ë¶„ì„ ë‹¨ê³„ ì—…ë°ì´íŠ¸
        async def update_step(step: int):
            if exam_id and db:
                try:
                    await db.table("exams").eq("id", exam_id).update({"analysis_step": step}).execute()
                except Exception as e:
                    print(f"[Step Update Error] {e}")

        # 1. ì‹œí—˜ì§€ ìœ í˜• ìë™ ë¶„ë¥˜
        classification = None
        exam_paper_type = "unknown"

        if auto_classify:
            await update_step(1)
            print("[Step 1] ì‹œí—˜ì§€ ìœ í˜• ë¶„ë¥˜ ì¤‘...")
            classification = await self.classify_exam_paper(file_path)
            exam_paper_type = classification.paper_type
            print(f"  - ìœ í˜•: {exam_paper_type} (ì‹ ë¢°ë„: {classification.confidence:.2f})")
            print(f"  - ì±„ì  ìƒíƒœ: {classification.grading_status}")

        # 2. exam_type ê²°ì •
        if exam_paper_type == "blank":
            exam_type = "blank"
        elif exam_paper_type in ["answered", "mixed"]:
            exam_type = "student"
        else:
            exam_type = "blank"  # ê¸°ë³¸ê°’

        # 3. ë™ì  í”„ë¡¬í”„íŠ¸ ìƒì„±
        await update_step(2)
        print("[Step 2] ë™ì  í”„ë¡¬í”„íŠ¸ ìƒì„± ì¤‘...")
        exam_context = ExamContext(
            grade_level=grade_level,
            subject="ìˆ˜í•™",
            unit=unit,
            exam_paper_type=exam_paper_type,
        )

        dynamic_prompt = await self.build_dynamic_prompt(
            db=db,
            exam_context=exam_context,
            include_error_patterns=(exam_type == "student"),
            include_examples=(exam_type == "student"),
        )

        # 4. AI ë¶„ì„ ì‹¤í–‰
        await update_step(3)
        print(f"[Step 3] AI ë¶„ì„ ì‹¤í–‰ ì¤‘... (exam_type={exam_type})")
        result = await self.analyze_exam_file(
            file_path=file_path,
            dynamic_prompt_additions="",  # ë™ì  í”„ë¡¬í”„íŠ¸ê°€ ì´ë¯¸ í¬í•¨ë¨
            exam_type=exam_type,
            custom_prompt=dynamic_prompt,
        )

        # 5. ë¶„ë¥˜ ê²°ê³¼ ì¶”ê°€
        if classification:
            result["_classification"] = {
                "paper_type": classification.paper_type,
                "paper_type_confidence": classification.confidence,
                "grading_status": classification.grading_status,
                "indicators": classification.indicators,
                "grading_indicators": classification.grading_indicators,
            }

        # 6. íŒ¨í„´ ë§¤ì¹­ (í–¥í›„ êµ¬í˜„)
        # TODO: ë¶„ì„ ê²°ê³¼ì—ì„œ íŒ¨í„´ ë§¤ì¹­ í›„ PatternMatchHistoryì— ê¸°ë¡

        return result

    # ============================================
    # 4. ê¸°ë³¸ ë¶„ì„ (ê¸°ì¡´ í˜¸í™˜)
    # ============================================
    async def analyze_exam_file(
        self,
        file_path: str,
        dynamic_prompt_additions: str = "",
        exam_type: str = "blank",
        custom_prompt: str | None = None,
    ) -> dict:
        """Analyze exam file (image or PDF) using Gemini.

        Args:
            file_path: ë¶„ì„í•  íŒŒì¼ ê²½ë¡œ (ì—¬ëŸ¬ ì´ë¯¸ì§€ì¸ ê²½ìš° ì½¤ë§ˆë¡œ êµ¬ë¶„)
            dynamic_prompt_additions: í•™ìŠµëœ íŒ¨í„´ì—ì„œ ë™ì ìœ¼ë¡œ ì¶”ê°€í•  í”„ë¡¬í”„íŠ¸ ë‚´ìš©
            exam_type: ì‹œí—˜ì§€ ìœ í˜• (blank: ë¹ˆ ì‹œí—˜ì§€, student: í•™ìƒ ë‹µì•ˆì§€)
            custom_prompt: ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ (ì§€ì • ì‹œ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ëŒ€ì²´)
        """
        if not self.client:
            raise HTTPException(
                status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
                detail="AI service is not configured (Missing API Key)."
            )

        # ì—¬ëŸ¬ íŒŒì¼ ê²½ë¡œ íŒŒì‹± (ì½¤ë§ˆ êµ¬ë¶„)
        file_paths = [p.strip() for p in file_path.split(",")]
        file_parts = []

        for fp in file_paths:
            file_content, mime_type = await self._load_file_content(fp)
            if file_content is None:
                raise FileNotFoundError(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {fp}")
            file_parts.append(types.Part.from_bytes(data=file_content, mime_type=mime_type))

        # ì—¬ëŸ¬ ì´ë¯¸ì§€ì¸ ê²½ìš° ì•ˆë‚´ ë©”ì‹œì§€ ì¶”ê°€
        multi_page_note = ""
        if len(file_parts) > 1:
            multi_page_note = f"\n\nâš ï¸ ì´ ì‹œí—˜ì§€ëŠ” {len(file_parts)}ê°œì˜ ì´ë¯¸ì§€ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ëª¨ë“  í˜ì´ì§€ì˜ ë¬¸ì œë¥¼ ë¹ ì§ì—†ì´ ë¶„ì„í•´ì£¼ì„¸ìš”.\n"

        try:
            # í”„ë¡¬í”„íŠ¸ ì„ íƒ
            if custom_prompt:
                prompt = custom_prompt
            elif exam_type == "student":
                prompt = self._get_student_prompt()
            else:
                prompt = self._get_blank_prompt()

            # ì—¬ëŸ¬ í˜ì´ì§€ ì•ˆë‚´ ë° í•™ìŠµëœ íŒ¨í„´ ì¶”ê°€
            prompt += multi_page_note
            if dynamic_prompt_additions:
                prompt += f"\n\n{dynamic_prompt_additions}"

            # íŒŒì¼ íŒŒíŠ¸ + í”„ë¡¬í”„íŠ¸ íŒŒíŠ¸ ê²°í•©
            all_parts = file_parts + [types.Part.from_text(text=prompt)]

            # Call Gemini with retry logic
            max_retries = 3
            last_error = None
            retry_prompt_addition = ""  # ëˆ„ë½ ê°ì§€ ì‹œ ì¶”ê°€í•  í”„ë¡¬í”„íŠ¸

            for attempt in range(max_retries):
                try:
                    # ì¬ë¶„ì„ ì‹œ ì¶”ê°€ í”„ë¡¬í”„íŠ¸ í¬í•¨
                    current_parts = file_parts + [types.Part.from_text(text=prompt + retry_prompt_addition)]

                    response = self.client.models.generate_content(
                        model=self.model_name,
                        contents=[
                            types.Content(
                                role="user",
                                parts=current_parts,
                            ),
                        ],
                        config=types.GenerateContentConfig(
                            response_mime_type="application/json",
                            temperature=0.1,
                            max_output_tokens=65536,  # Gemini 2.5 Flash max
                        ),
                    )

                    # Check finish reason
                    if response.candidates:
                        candidate = response.candidates[0]
                        finish_reason = getattr(candidate, 'finish_reason', None)
                        print(f"[Attempt {attempt + 1}] Finish reason: {finish_reason}")

                        if finish_reason and "MAX_TOKENS" in str(finish_reason):
                            # 65536 í† í°ì—ì„œë„ ì˜ë¦¬ë©´ ë” ì´ìƒ ì¬ì‹œë„ ë¶ˆê°€
                            raise ValueError(
                                "ì‘ë‹µì´ ìµœëŒ€ í† í° í•œë„(65536)ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. "
                                "ì‹œí—˜ì§€ ì´ë¯¸ì§€ê°€ ë„ˆë¬´ ë³µì¡í•˜ê±°ë‚˜ ë¬¸ì œ ìˆ˜ê°€ ë§ìŠµë‹ˆë‹¤."
                            )

                    # Parse JSON
                    if not response.text:
                        raise ValueError("Empty response from AI")

                    result = self._parse_json_response(response.text)

                    # ê²€ì¦ ë° ì‹ ë¢°ë„ ê³„ì‚°
                    validated_result, confidence = self._validate_result(result, exam_type)
                    print(f"[Analysis] Confidence: {confidence:.2f}, Questions: {len(validated_result.get('questions', []))}")

                    # ëˆ„ë½ ê°ì§€ ì‹œ 1íšŒ ì¬ë¶„ì„ ì‹œë„
                    missing_nums = validated_result.get("_missing_questions", [])
                    if missing_nums and attempt == 0:
                        print(f"[Analysis] ëˆ„ë½ ê°ì§€ë¨: {missing_nums}, ì¬ë¶„ì„ ì‹œë„...")
                        retry_prompt_addition = f"""

âš ï¸ **ì¬ë¶„ì„ ìš”ì²­** - ë‹¤ìŒ ë¬¸í•­ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {missing_nums}

ìœ„ì¹˜ ê¸°ë°˜ìœ¼ë¡œ ë²ˆí˜¸ë¥¼ ì¶”ë¡ í•´ì„œ **ë°˜ë“œì‹œ** ì´ ë²ˆí˜¸ë“¤ì„ í¬í•¨í•´ì£¼ì„¸ìš”.
- 1ë²ˆ ë‹¤ìŒì— ë‚˜ì˜¤ëŠ” ë¬¸ì œ â†’ 2ë²ˆ
- Në²ˆ ë‹¤ìŒì— ë‚˜ì˜¤ëŠ” ë¬¸ì œ â†’ N+1ë²ˆ
- ë²ˆí˜¸ê°€ ê°€ë ¤ì ¸ë„ ìˆœì„œëŒ€ë¡œ ë²ˆí˜¸ ë¶€ì—¬

ëˆ„ë½ ì—†ì´ ë‹¤ì‹œ ë¶„ì„í•´ì£¼ì„¸ìš”.
"""
                        continue  # ë‹¤ìŒ attemptë¡œ ì¬ì‹œë„ (retry_prompt_addition í¬í•¨ë¨)

                    return validated_result

                except json.JSONDecodeError as e:
                    last_error = e
                    print(f"[Attempt {attempt + 1}] JSON parse error: {e}")
                    print(f"Response text (first 500 chars): {response.text[:500] if response.text else 'None'}")
                    continue
                except Exception as e:
                    last_error = e
                    print(f"[Attempt {attempt + 1}] Error: {e}")
                    continue

            # All retries failed
            raise ValueError(f"Failed after {max_retries} attempts. Last error: {last_error}")

        except Exception as e:
            print(f"AI Analysis Error: {e}")
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail=f"AI Analysis failed: {str(e)}"
            )

    def _validate_result(self, result: dict, exam_type: str = "blank") -> tuple[dict, float]:
        """ë¶„ì„ ê²°ê³¼ ê²€ì¦ ë° ì‹ ë¢°ë„ ì ìˆ˜ ê³„ì‚°."""
        confidence = 1.0
        issues = []

        # 1. í•„ìˆ˜ í•„ë“œ ê²€ì¦
        if "summary" not in result:
            result["summary"] = self._empty_summary()
            confidence -= 0.3
            issues.append("summary ëˆ„ë½")

        if "questions" not in result or not result["questions"]:
            confidence -= 0.5
            issues.append("questions ëˆ„ë½")

        # 2. ë¬¸í•­ë³„ ê²€ì¦
        valid_difficulties = {"high", "medium", "low"}
        valid_types = {"calculation", "geometry", "application", "proof", "graph", "statistics"}

        for i, q in enumerate(result.get("questions", [])):
            q_confidence = q.get("confidence", 0.9)

            # ë‚œì´ë„ ê²€ì¦
            if q.get("difficulty") not in valid_difficulties:
                q["difficulty"] = "medium"
                confidence -= 0.05
                q_confidence -= 0.15
                issues.append(f"Q{i+1}: ì˜ëª»ëœ ë‚œì´ë„")

            # ìœ í˜• ê²€ì¦
            if q.get("question_type") not in valid_types:
                q["question_type"] = "calculation"
                confidence -= 0.05
                q_confidence -= 0.15
                issues.append(f"Q{i+1}: ì˜ëª»ëœ ìœ í˜•")

            # í† í”½ í˜•ì‹ ê²€ì¦
            topic = q.get("topic", "")
            if topic and " > " not in topic:
                confidence -= 0.03
                q_confidence -= 0.1
                issues.append(f"Q{i+1}: í† í”½ í˜•ì‹ ì˜¤ë¥˜")

            # ë°°ì  ê²€ì¦
            points = q.get("points")
            if points is None or points <= 0:
                q["points"] = 4
                confidence -= 0.02
                q_confidence -= 0.05

            # í•™ìƒ ë‹µì•ˆì§€ìš© í•„ë“œ ê²€ì¦
            if exam_type == "student":
                valid_error_types = {
                    "calculation_error", "concept_error", "careless_mistake",
                    "process_error", "incomplete", None
                }
                error_type = q.get("error_type")
                if error_type and error_type not in valid_error_types:
                    q["error_type"] = "concept_error"
                    q_confidence -= 0.05

                if "is_correct" not in q:
                    q["is_correct"] = None

                if "earned_points" not in q:
                    if q.get("is_correct") is True:
                        q["earned_points"] = q.get("points", 0)
                    elif q.get("is_correct") is False:
                        q["earned_points"] = 0
                    else:
                        q["earned_points"] = None

            q["confidence"] = round(max(0.0, min(1.0, q_confidence)), 2)

        # 3. ë¬¸í•­ ë²ˆí˜¸ ì—°ì†ì„± ê²€ì¦ (ëˆ„ë½ ê°ì§€)
        if result.get("questions"):
            question_numbers = []
            for q in result["questions"]:
                qnum = q.get("question_number")
                if isinstance(qnum, int):
                    question_numbers.append(qnum)
                elif isinstance(qnum, str) and qnum.isdigit():
                    question_numbers.append(int(qnum))

            if question_numbers:
                question_numbers.sort()
                expected_nums = list(range(1, max(question_numbers) + 1))
                missing_nums = set(expected_nums) - set(question_numbers)

                if missing_nums:
                    confidence -= 0.1 * len(missing_nums)
                    issues.append(f"ëˆ„ë½ëœ ë¬¸í•­: {sorted(missing_nums)}")
                    result["_missing_questions"] = sorted(missing_nums)
                    print(f"[Validation] âš ï¸ ëˆ„ë½ëœ ë¬¸í•­ ë²ˆí˜¸: {sorted(missing_nums)}")

        # 4. ë¶„í¬ ì¼ì¹˜ ê²€ì¦
        if result.get("questions"):
            actual_diff = {"high": 0, "medium": 0, "low": 0}
            actual_type: dict[str, int] = {}

            for q in result["questions"]:
                diff = q.get("difficulty", "medium")
                actual_diff[diff] = actual_diff.get(diff, 0) + 1

                qtype = q.get("question_type", "calculation")
                actual_type[qtype] = actual_type.get(qtype, 0) + 1

            result["summary"]["difficulty_distribution"] = actual_diff
            result["summary"]["type_distribution"] = {
                "calculation": actual_type.get("calculation", 0),
                "geometry": actual_type.get("geometry", 0),
                "application": actual_type.get("application", 0),
                "proof": actual_type.get("proof", 0),
                "graph": actual_type.get("graph", 0),
                "statistics": actual_type.get("statistics", 0),
            }

        # 5. ì‹ ë¢°ë„ ì ìˆ˜ ë°˜í™˜
        confidence = max(0.0, min(1.0, confidence))

        if issues:
            print(f"[Validation] Issues found: {issues}")
            print(f"[Validation] Confidence: {confidence:.2f}")

        result["_confidence"] = round(confidence, 2)
        result["_validation_issues"] = issues

        return result, confidence

    def _empty_summary(self) -> dict:
        """ë¹ˆ summary ìƒì„±."""
        return {
            "difficulty_distribution": {"high": 0, "medium": 0, "low": 0},
            "type_distribution": {
                "calculation": 0, "geometry": 0, "application": 0,
                "proof": 0, "graph": 0, "statistics": 0
            },
            "average_difficulty": "medium",
            "dominant_type": "calculation"
        }

    def _parse_json_response(self, text: str) -> dict:
        """Gemini ì‘ë‹µì—ì„œ JSON íŒŒì‹± (í›„í–‰ ì‰¼í‘œ ë“± ì •ë¦¬)."""
        import re

        json_text = text.strip()

        # ì½”ë“œ ë¸”ë¡ ë§ˆì»¤ ì œê±°
        if json_text.startswith("```"):
            json_text = json_text.split("\n", 1)[1] if "\n" in json_text else json_text[3:]
        if json_text.endswith("```"):
            json_text = json_text[:-3]
        json_text = json_text.strip()

        try:
            return json.loads(json_text)
        except json.JSONDecodeError:
            # í›„í–‰ ì‰¼í‘œ ì œê±° ì‹œë„
            cleaned = re.sub(r',(\s*[}\]])', r'\1', json_text)
            return json.loads(cleaned)

    def _get_mime_type(self, file_path: Path) -> str:
        """íŒŒì¼ í™•ì¥ìë¡œ MIME íƒ€ì… ê²°ì •."""
        suffix = file_path.suffix.lower()
        if suffix == ".png":
            return "image/png"
        elif suffix == ".pdf":
            return "application/pdf"
        elif suffix in [".jpg", ".jpeg"]:
            return "image/jpeg"
        else:
            return "image/jpeg"

    def _get_mime_type_from_path(self, file_path: str) -> str:
        """íŒŒì¼ ê²½ë¡œ ë¬¸ìì—´ì—ì„œ MIME íƒ€ì… ê²°ì •."""
        path_lower = file_path.lower()
        if path_lower.endswith(".png"):
            return "image/png"
        elif path_lower.endswith(".pdf"):
            return "application/pdf"
        elif path_lower.endswith(".jpg") or path_lower.endswith(".jpeg"):
            return "image/jpeg"
        else:
            return "image/jpeg"

    async def _load_file_content(self, file_path: str) -> tuple[bytes | None, str]:
        """íŒŒì¼ ê²½ë¡œì—ì„œ ì½˜í…ì¸ ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.

        ë¡œì»¬ íŒŒì¼ ë˜ëŠ” Supabase Storageì—ì„œ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.

        Args:
            file_path: íŒŒì¼ ê²½ë¡œ (ë¡œì»¬ ë˜ëŠ” supabase://...)

        Returns:
            (file_content, mime_type) íŠœí”Œ
        """
        from app.services.file_storage import file_storage

        if file_path.startswith("supabase://"):
            # Supabase Storageì—ì„œ ë‹¤ìš´ë¡œë“œ
            try:
                content = await file_storage.download_file(file_path)
                mime_type = self._get_mime_type_from_path(file_path)
                print(f"[FileLoad] Downloaded from Supabase: {file_path[:50]}... ({len(content)} bytes)")
                return content, mime_type
            except Exception as e:
                print(f"[FileLoad] Supabase download failed: {e}")
                return None, ""
        else:
            # ë¡œì»¬ íŒŒì¼
            path = Path(file_path)
            if not path.exists():
                print(f"[FileLoad] Local file not found: {file_path}")
                return None, ""
            content = path.read_bytes()
            mime_type = self._get_mime_type(path)
            print(f"[FileLoad] Read local file: {file_path} ({len(content)} bytes)")
            return content, mime_type

    def _get_blank_prompt(self) -> str:
        """ë¹ˆ ì‹œí—˜ì§€ìš© ê¸°ë³¸ í”„ë¡¬í”„íŠ¸"""
        return """
ë‹¹ì‹ ì€ í•œêµ­ ê³ ë“±í•™êµ ìˆ˜í•™ ì‹œí—˜ì§€ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

## ë¶„ì„ ë‹¨ê³„ (Chain of Thought)

### STEP 1: ë¬¸ì œ ì¶”ì¶œ (âš ï¸ ëˆ„ë½ ê¸ˆì§€)
ì‹œí—˜ì§€ë¥¼ ì£¼ì˜ ê¹Šê²Œ ì‚´í´ë³´ê³  ë‹¤ìŒì„ íŒŒì•…í•˜ì„¸ìš”:
- ì´ ë¬¸í•­ ìˆ˜ (ê°ê´€ì‹ + ì„œë‹µí˜•)
- ê° ë¬¸í•­ì˜ ë²ˆí˜¸ì™€ ë°°ì 
- ì„œë‹µí˜• ë¬¸ì œì˜ ì†Œë¬¸ì œ êµ¬ì¡°

âš ï¸ **í•„ìˆ˜**: 1ë²ˆë¶€í„° ë§ˆì§€ë§‰ ë¬¸í•­ê¹Œì§€ **ë¹ ì§ì—†ì´** ëª¨ë‘ ë¶„ì„í•˜ì„¸ìš”.
- ë¬¸í•­ ë²ˆí˜¸ê°€ ì—°ì†ì ì¸ì§€ í™•ì¸ (1, 2, 3, ... ìˆœì„œ)
- ì±„ì  í‘œì‹œ(X, O, âœ“)ê°€ ìˆì–´ë„ í•´ë‹¹ ë¬¸í•­ì„ ë°˜ë“œì‹œ í¬í•¨
- ì†ê¸€ì”¨ë‚˜ í‘œì‹œê°€ ë§ì•„ë„ ë¬¸í•­ ë²ˆí˜¸ë¥¼ ì •í™•íˆ ì¸ì‹

ğŸ”¢ **ë²ˆí˜¸ ì¶”ë¡  ê·œì¹™**:
- ë²ˆí˜¸ê°€ ê°€ë ¤ì§€ê±°ë‚˜ ì•ˆ ë³´ì—¬ë„, **ìœ„ì¹˜ë¡œ ë²ˆí˜¸ë¥¼ ì¶”ë¡ **í•˜ì„¸ìš”
- 1ë²ˆ ë‹¤ìŒì— ë‚˜ì˜¤ëŠ” ë¬¸ì œ â†’ 2ë²ˆ
- Në²ˆ ë‹¤ìŒì— ë‚˜ì˜¤ëŠ” ë¬¸ì œ â†’ N+1ë²ˆ
- í° X í‘œì‹œë‚˜ ì±„ì  ë§ˆí¬ë¡œ ë²ˆí˜¸ê°€ ê°€ë ¤ì ¸ë„ ìˆœì„œëŒ€ë¡œ ë²ˆí˜¸ ë¶€ì—¬

### STEP 2: ë¬¸í•­ë³„ ë¶„ë¥˜
ê° ë¬¸í•­ì— ëŒ€í•´:
1. ì–´ë–¤ ê°œë…ì„ ë¬»ëŠ”ê°€? â†’ í† í”½ ë¶„ë¥˜
2. ì–¼ë§ˆë‚˜ ì–´ë ¤ìš´ê°€? â†’ ë‚œì´ë„ íŒì •
3. ì–´ë–¤ ìœ í˜•ì¸ê°€? â†’ ë¬¸ì œ ìœ í˜•

### STEP 3: JSON ì¶œë ¥
ì•„ë˜ í˜•ì‹ìœ¼ë¡œ ì •í™•í•˜ê²Œ ì¶œë ¥í•˜ì„¸ìš”:

{
    "exam_info": {
        "total_questions": 16,
        "total_points": 100,
        "objective_count": 12,
        "subjective_count": 4
    },
    "summary": {
        "difficulty_distribution": {"high": 0, "medium": 0, "low": 0},
        "type_distribution": {
            "calculation": 0, "geometry": 0, "application": 0,
            "proof": 0, "graph": 0, "statistics": 0
        },
        "average_difficulty": "medium",
        "dominant_type": "calculation"
    },
    "questions": [
        {
            "question_number": 1,
            "difficulty": "low",
            "question_type": "calculation",
            "points": 3,
            "topic": "ê³µí†µìˆ˜í•™1 > ë‹¤í•­ì‹ > ë‹¤í•­ì‹ì˜ ì—°ì‚°",
            "ai_comment": "í•µì‹¬ ê°œë…. ì£¼ì˜ì‚¬í•­.",
            "confidence": 0.95
        }
    ]
}

## í† í”½ ë¶„ë¥˜í‘œ (ì •í™•íˆ ì‚¬ìš©)

[ê³µí†µìˆ˜í•™1]
- ë‹¤í•­ì‹: ë‹¤í•­ì‹ì˜ ì—°ì‚°, í•­ë“±ì‹ê³¼ ë‚˜ë¨¸ì§€ì •ë¦¬, ì¸ìˆ˜ë¶„í•´
- ë°©ì •ì‹ê³¼ ë¶€ë“±ì‹: ë³µì†Œìˆ˜, ì´ì°¨ë°©ì •ì‹, ì´ì°¨ë°©ì •ì‹ê³¼ ì´ì°¨í•¨ìˆ˜, ì—¬ëŸ¬ ê°€ì§€ ë°©ì •ì‹, ì—¬ëŸ¬ ê°€ì§€ ë¶€ë“±ì‹
- ê²½ìš°ì˜ ìˆ˜: ê²½ìš°ì˜ ìˆ˜ì™€ ìˆœì—´, ì¡°í•©

[ê³µí†µìˆ˜í•™2]
- ë„í˜•ì˜ ë°©ì •ì‹: í‰ë©´ì¢Œí‘œ, ì§ì„ ì˜ ë°©ì •ì‹, ì›ì˜ ë°©ì •ì‹, ë„í˜•ì˜ ì´ë™
- ì§‘í•©ê³¼ ëª…ì œ: ì§‘í•©ì˜ ëœ», ì§‘í•©ì˜ ì—°ì‚°, ëª…ì œ
- í•¨ìˆ˜: í•©ì„±í•¨ìˆ˜ì™€ ì—­í•¨ìˆ˜, ìœ ë¦¬í•¨ìˆ˜, ë¬´ë¦¬í•¨ìˆ˜

[ìˆ˜í•™1]
- ì§€ìˆ˜í•¨ìˆ˜ì™€ ë¡œê·¸í•¨ìˆ˜: ì§€ìˆ˜, ë¡œê·¸, ì§€ìˆ˜í•¨ìˆ˜, ë¡œê·¸í•¨ìˆ˜
- ì‚¼ê°í•¨ìˆ˜: ì‚¼ê°í•¨ìˆ˜ì˜ ì •ì˜, ì‚¼ê°í•¨ìˆ˜ì˜ ê·¸ë˜í”„, ì‚¼ê°í•¨ìˆ˜ì˜ í™œìš©
- ìˆ˜ì—´: ë“±ì°¨ìˆ˜ì—´ê³¼ ë“±ë¹„ìˆ˜ì—´, ìˆ˜ì—´ì˜ í•©, ìˆ˜í•™ì  ê·€ë‚©ë²•

[ìˆ˜í•™2]
- í•¨ìˆ˜ì˜ ê·¹í•œê³¼ ì—°ì†: í•¨ìˆ˜ì˜ ê·¹í•œ, í•¨ìˆ˜ì˜ ì—°ì†
- ë¯¸ë¶„: ë¯¸ë¶„ê³„ìˆ˜ì™€ ë„í•¨ìˆ˜, ë„í•¨ìˆ˜ì˜ í™œìš©
- ì ë¶„: ë¶€ì •ì ë¶„, ì •ì ë¶„, ì •ì ë¶„ì˜ í™œìš©

[í™•ë¥ ê³¼ í†µê³„]
- ê²½ìš°ì˜ ìˆ˜: ìˆœì—´ê³¼ ì¡°í•©, ì´í•­ì •ë¦¬
- í™•ë¥ : í™•ë¥ ì˜ ëœ»ê³¼ í™œìš©, ì¡°ê±´ë¶€ í™•ë¥ 
- í†µê³„: í™•ë¥ ë¶„í¬, í†µê³„ì  ì¶”ì •

[ë¯¸ì ë¶„]
- ìˆ˜ì—´ì˜ ê·¹í•œ: ìˆ˜ì—´ì˜ ê·¹í•œ, ê¸‰ìˆ˜
- ë¯¸ë¶„ë²•: ì—¬ëŸ¬ ê°€ì§€ í•¨ìˆ˜ì˜ ë¯¸ë¶„, ì—¬ëŸ¬ ê°€ì§€ ë¯¸ë¶„ë²•, ë„í•¨ìˆ˜ì˜ í™œìš©
- ì ë¶„ë²•: ì—¬ëŸ¬ ê°€ì§€ ì ë¶„ë²•, ì •ì ë¶„, ì •ì ë¶„ì˜ í™œìš©

[ê¸°í•˜]
- ì´ì°¨ê³¡ì„ : ì´ì°¨ê³¡ì„ , ì´ì°¨ê³¡ì„ ê³¼ ì§ì„ 
- í‰ë©´ë²¡í„°: ë²¡í„°ì˜ ì—°ì‚°, í‰ë©´ë²¡í„°ì˜ ì„±ë¶„ê³¼ ë‚´ì 
- ê³µê°„ë„í˜•ê³¼ ê³µê°„ì¢Œí‘œ: ê³µê°„ë„í˜•, ê³µê°„ì¢Œí‘œ

## ê·œì¹™ (ì—„ê²© ì¤€ìˆ˜)

1. ëª¨ë“  í…ìŠ¤íŠ¸(topic, ai_comment)ëŠ” í•œêµ­ì–´ë¡œ ì‘ì„±
2. difficulty: high(ìƒ), medium(ì¤‘), low(í•˜) ì¤‘ í•˜ë‚˜
3. question_type: calculation(ê³„ì‚°), geometry(ë„í˜•), application(ì‘ìš©), proof(ì¦ëª…), graph(ê·¸ë˜í”„), statistics(í†µê³„) ì¤‘ í•˜ë‚˜
4. points: ìˆ«ì (ì†Œìˆ˜ì  í—ˆìš©)
5. ì„œë‹µí˜•ì€ "ì„œë‹µí˜• 1", "ì„œë‹µí˜• 2" í˜•ì‹

âš ï¸ ì¤‘ìš” - ì†Œë¬¸ì œ ì²˜ë¦¬:
- (1), (2), (3) ë˜ëŠ” (ê°€), (ë‚˜), (ë‹¤)ê°€ ìˆìœ¼ë©´ í•˜ë‚˜ì˜ ë¬¸ì œë¡œ ì·¨ê¸‰
- ë°°ì ì€ í•©ì‚°
- ë‚œì´ë„ëŠ” ê°€ì¥ ì–´ë ¤ìš´ ì†Œë¬¸ì œ ê¸°ì¤€

6. topic í˜•ì‹: "ê³¼ëª©ëª… > ëŒ€ë‹¨ì› > ì†Œë‹¨ì›"
7. ai_comment: ì •í™•íˆ 2ë¬¸ì¥, ì´ 50ì ì´ë‚´
8. confidence: í•´ë‹¹ ë¬¸í•­ ë¶„ì„ì˜ í™•ì‹ ë„ (0.0 ~ 1.0)
"""

    def _get_student_prompt(self) -> str:
        """í•™ìƒ ë‹µì•ˆì§€ìš© ê¸°ë³¸ í”„ë¡¬í”„íŠ¸"""
        return """
ë‹¹ì‹ ì€ í•œêµ­ ê³ ë“±í•™êµ ìˆ˜í•™ ì‹œí—˜ì§€ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì´ê²ƒì€ **í•™ìƒì´ í‘¼ ì‹œí—˜ì§€**ì…ë‹ˆë‹¤. ì •ì˜¤ë‹µ ë¶„ì„ì´ í•„ìš”í•©ë‹ˆë‹¤.

## ë¶„ì„ ë‹¨ê³„ (Chain of Thought)

### STEP 1: ë¬¸ì œ ë° ì±„ì  ì¶”ì¶œ (âš ï¸ ëˆ„ë½ ê¸ˆì§€)
ì‹œí—˜ì§€ë¥¼ ì£¼ì˜ ê¹Šê²Œ ì‚´í´ë³´ê³  ë‹¤ìŒì„ íŒŒì•…í•˜ì„¸ìš”:
- ì´ ë¬¸í•­ ìˆ˜ (ê°ê´€ì‹ + ì„œë‹µí˜•)
- ê° ë¬¸í•­ì˜ ë²ˆí˜¸ì™€ ë°°ì 
- **ì •ë‹µ/ì˜¤ë‹µ í‘œì‹œ ì¸ì‹** (O, X, âœ“, âœ—, ë¹¨ê°„íœ, ë™ê·¸ë¼ë¯¸ ë“±)
- **í•™ìƒì´ ì‘ì„±í•œ ë‹µì•ˆ** (ì„ íƒì§€ ë²ˆí˜¸, ì„œìˆ  ë‚´ìš© ë“±)
- **íšë“ ì ìˆ˜** (ë¶€ë¶„ ì ìˆ˜ í¬í•¨)

âš ï¸ **í•„ìˆ˜**: 1ë²ˆë¶€í„° ë§ˆì§€ë§‰ ë¬¸í•­ê¹Œì§€ **ë¹ ì§ì—†ì´** ëª¨ë‘ ë¶„ì„í•˜ì„¸ìš”.
- ë¬¸í•­ ë²ˆí˜¸ê°€ ì—°ì†ì ì¸ì§€ í™•ì¸ (1, 2, 3, ... ìˆœì„œ)
- ì±„ì  í‘œì‹œ(X, O, âœ“)ê°€ í¬ê²Œ í‘œì‹œë˜ì–´ ìˆì–´ë„ í•´ë‹¹ ë¬¸í•­ì„ ë°˜ë“œì‹œ í¬í•¨
- ì†ê¸€ì”¨, ë¹¨ê°„íœ í‘œì‹œê°€ ë§ì•„ë„ ë¬¸í•­ ë²ˆí˜¸ë¥¼ ì •í™•íˆ ì¸ì‹
- í‹€ë¦° ë¬¸ì œë„ ê±´ë„ˆë›°ì§€ ë§ê³  ë°˜ë“œì‹œ ë¶„ì„ì— í¬í•¨

ğŸ”¢ **ë²ˆí˜¸ ì¶”ë¡  ê·œì¹™**:
- ë²ˆí˜¸ê°€ ê°€ë ¤ì§€ê±°ë‚˜ ì•ˆ ë³´ì—¬ë„, **ìœ„ì¹˜ë¡œ ë²ˆí˜¸ë¥¼ ì¶”ë¡ **í•˜ì„¸ìš”
- 1ë²ˆ ë‹¤ìŒì— ë‚˜ì˜¤ëŠ” ë¬¸ì œ â†’ 2ë²ˆ
- Në²ˆ ë‹¤ìŒì— ë‚˜ì˜¤ëŠ” ë¬¸ì œ â†’ N+1ë²ˆ
- í° X í‘œì‹œë‚˜ ì±„ì  ë§ˆí¬ë¡œ ë²ˆí˜¸ê°€ ê°€ë ¤ì ¸ë„ ìˆœì„œëŒ€ë¡œ ë²ˆí˜¸ ë¶€ì—¬

### STEP 2: ë¬¸í•­ë³„ ë¶„ë¥˜ + ì •ì˜¤ë‹µ ë¶„ì„
ê° ë¬¸í•­ì— ëŒ€í•´:
1. ì–´ë–¤ ê°œë…ì„ ë¬»ëŠ”ê°€? â†’ í† í”½ ë¶„ë¥˜
2. ì–¼ë§ˆë‚˜ ì–´ë ¤ìš´ê°€? â†’ ë‚œì´ë„ íŒì •
3. ì–´ë–¤ ìœ í˜•ì¸ê°€? â†’ ë¬¸ì œ ìœ í˜•
4. **ì •ë‹µì¸ê°€ ì˜¤ë‹µì¸ê°€?** â†’ is_correct
5. **ì˜¤ë‹µì¼ ê²½ìš° ì˜¤ë¥˜ ìœ í˜•** â†’ error_type

### STEP 3: JSON ì¶œë ¥

{
    "exam_info": {
        "total_questions": 16,
        "total_points": 100,
        "objective_count": 12,
        "subjective_count": 4,
        "earned_total_points": 72,
        "correct_count": 10,
        "wrong_count": 6
    },
    "summary": {
        "difficulty_distribution": {"high": 0, "medium": 0, "low": 0},
        "type_distribution": {
            "calculation": 0, "geometry": 0, "application": 0,
            "proof": 0, "graph": 0, "statistics": 0
        },
        "average_difficulty": "medium",
        "dominant_type": "calculation"
    },
    "questions": [
        {
            "question_number": 1,
            "difficulty": "low",
            "question_type": "calculation",
            "points": 3,
            "topic": "ê³µí†µìˆ˜í•™1 > ë‹¤í•­ì‹ > ë‹¤í•­ì‹ì˜ ì—°ì‚°",
            "ai_comment": "í•µì‹¬ ê°œë…. ì£¼ì˜ì‚¬í•­.",
            "confidence": 0.95,
            "is_correct": true,
            "student_answer": "3",
            "earned_points": 3,
            "error_type": null
        },
        {
            "question_number": 2,
            "difficulty": "medium",
            "question_type": "calculation",
            "points": 4,
            "topic": "ê³µí†µìˆ˜í•™1 > ë°©ì •ì‹ê³¼ ë¶€ë“±ì‹ > ì´ì°¨ë°©ì •ì‹",
            "ai_comment": "ê·¼ì˜ ê³µì‹ í™œìš©. íŒë³„ì‹ ì£¼ì˜.",
            "confidence": 0.90,
            "is_correct": false,
            "student_answer": "2",
            "earned_points": 0,
            "error_type": "calculation_error"
        }
    ]
}

## ì˜¤ë¥˜ ìœ í˜• (error_type)

- calculation_error: ê³„ì‚° ì‹¤ìˆ˜ (ë¶€í˜¸, ì‚¬ì¹™ì—°ì‚° ë“±)
- concept_error: ê°œë… ì˜¤í•´ (ê³µì‹, ì •ì˜ ë“±)
- careless_mistake: ë‹¨ìˆœ ì‹¤ìˆ˜ (ë¬¸ì œ ì˜ëª» ì½ìŒ, ë‹µì•ˆ ì˜ëª» ê¸°ì¬)
- process_error: í’€ì´ ê³¼ì • ì˜¤ë¥˜ (ë…¼ë¦¬ì  ë¹„ì•½)
- incomplete: ë¯¸ì™„ì„± (ì‹œê°„ ë¶€ì¡±, í¬ê¸°)

## ê·œì¹™ (ì—„ê²© ì¤€ìˆ˜)

1. ëª¨ë“  í…ìŠ¤íŠ¸(topic, ai_comment)ëŠ” í•œêµ­ì–´ë¡œ ì‘ì„±
2. difficulty: high(ìƒ), medium(ì¤‘), low(í•˜) ì¤‘ í•˜ë‚˜
3. question_type: calculation, geometry, application, proof, graph, statistics ì¤‘ í•˜ë‚˜
4. points: ìˆ«ì

âš ï¸ ì¤‘ìš” - ì •ì˜¤ë‹µ ì¸ì‹:
- O, â—‹, âœ“, ë™ê·¸ë¼ë¯¸ = ì •ë‹µ (is_correct: true)
- X, âœ—, ë¹—ê¸ˆ, ë¹¨ê°„ ì¤„ = ì˜¤ë‹µ (is_correct: false)
- ë¶€ë¶„ ì ìˆ˜ê°€ ìˆìœ¼ë©´ earned_pointsì— ë°˜ì˜
- ì±„ì  í‘œì‹œê°€ ì—†ìœ¼ë©´ is_correct: null

5. topic í˜•ì‹: "ê³¼ëª©ëª… > ëŒ€ë‹¨ì› > ì†Œë‹¨ì›"
6. ai_comment: ì •í™•íˆ 2ë¬¸ì¥, ì´ 50ì ì´ë‚´
7. confidence: í•´ë‹¹ ë¬¸í•­ ë¶„ì„ì˜ í™•ì‹ ë„ (0.0 ~ 1.0)
"""


ai_engine = AIEngine()
